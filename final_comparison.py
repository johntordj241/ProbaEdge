#!/usr/bin/env python3
"""Comparatif final de tous les modÃ¨les testÃ©s"""

import json
from pathlib import Path

print("=" * 100)
print("ğŸ“Š COMPARATIF FINAL - TOUS LES MODÃˆLES")
print("=" * 100)

models = {
    "1. Baseline (Random)": {
        "accuracy": 0.500,
        "roc_auc": 0.500,
        "features": 0,
        "description": "Lancer une piÃ¨ce",
    },
    "2. INITIAL (6 features)": {
        "accuracy": 0.612,
        "roc_auc": 0.696,
        "features": 6,
        "description": "feature_*diff, max_prob, confidence_norm, total_pick_over",
    },
    "3. Enhanced (12 features)": {
        "accuracy": 0.621,
        "roc_auc": 0.691,
        "features": 12,
        "description": "Init + prob_home/draw/away + prob_over/under + confidence",
    },
    "4. Optimized (8 features)": {
        "accuracy": 0.621,
        "roc_auc": 0.689,
        "features": 8,
        "description": "Top 8 features par importance",
    },
    "5. Ultimate (11 features)": {
        "accuracy": 0.612,
        "roc_auc": 0.688,
        "features": 11,
        "description": "Init + Elo ratings + Lambda (buts attendus)",
    },
}

print(f"\n{'ModÃ¨le':<30} | Accuracy | ROC-AUC | Features | vs Baseline")
print(f"{'-' * 100}")

best_accuracy_model = None
best_roc_model = None
best_acc = 0
best_roc = 0

for name, data in models.items():
    acc_pct = data["accuracy"] * 100
    roc_pct = data["roc_auc"] * 100
    acc_gain = (data["accuracy"] - 0.5) * 100
    roc_gain = (data["roc_auc"] - 0.5) * 100

    print(
        f"{name:<30} | {acc_pct:7.1f}% | {roc_pct:5.1f}% | {data['features']:8d} | +{acc_gain:5.1f}% acc, +{roc_gain:5.1f}% AUC"
    )

    if data["roc_auc"] > best_roc:
        best_roc = data["roc_auc"]
        best_roc_model = name
    if data["accuracy"] > best_acc:
        best_acc = data["accuracy"]
        best_accuracy_model = name

print(f"\n" + "=" * 100)
print("ğŸ† MEILLEUR MODÃˆLE")
print("=" * 100)
print(f"\nâœ… Meilleur ROC-AUC: {best_roc_model}")
print(f"   {models[best_roc_model]['description']}")
print(f"   Performance: Accuracy {best_acc*100:.1f}% | ROC-AUC {best_roc*100:.1f}%")

print(f"\nğŸ’¡ CONCLUSION")
print(
    f"""
Tous les modÃ¨les performent Ã  peu prÃ¨s pareil (60-62% accuracy, 69% ROC-AUC).
Cela signifie que:

1. âœ… Tes 6 features ORIGINALES Ã©taient dÃ©jÃ  excellentes
2. âœ… Ajouter plus de features ne les amÃ©liore pas (car redondantes)
3. âœ… Le modÃ¨le a atteint un plateau - amÃ©liorations margales

RECOMMANDATION pour la PRODUCTION:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â†’ Utiliser le modÃ¨le INITIAL (6 features)
  â€¢ Plus simple (moins de risque overfitting)
  â€¢ Exactement la mÃªme performance
  â€¢ Plus rapide Ã  entraÃ®ner
  â€¢ Chemin: models/prediction_success_model_v2.joblib

Alternative si tu veux tester:
â†’ ModÃ¨le ENHANCED (12 features) - performance identique mais plus complet
  â€¢ Plus d'information capturÃ©e
  â€¢ Pour du deep learning futur
"""
)

print(f"\n" + "=" * 100)
print("ğŸ“ˆ POUR VRAIMENT AMÃ‰LIORER DE 5%+, IL FAUDRAIT:")
print("=" * 100)
print(
    """
Option A: Meilleure data
  âœ— Ajouter plus de matchs historiques (500+ au lieu de 411)
  âœ— IntÃ©grer des donnÃ©es de joueurs (blessures, absences)
  âœ— Ajouter contexte (mÃ©tÃ©o, fatigue, suspensions)

Option B: Meilleur modÃ¨le
  âœ— Random Forest / XGBoost (au lieu de Logistic Regression)
  âœ— Neural Networks (Deep Learning)
  âœ— Ensemble methods (combiner plusieurs modÃ¨les)

Option C: Features crÃ©atives
  âœ— Momentum rÃ©cent (forme derniers 5 matchs)
  âœ— Head-to-head historique
  âœ— Avantage domicile par compÃ©tition
  âœ— Tendances saisonniÃ¨res
  âœ— Arbitres connus pour Ãªtre agressifs/permissifs
"""
)

print(f"\nâœ… TON MODÃˆLE ACTUEL EST BON POUR COMMENCER!")
print(f"   60%+ de prÃ©cision en prÃ©diction sportive = trÃ¨s respectable ğŸ’ª\n")
